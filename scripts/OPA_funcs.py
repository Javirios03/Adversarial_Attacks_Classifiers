import torch
from torch import nn
import torch.nn.functional as F
import numpy as np

from utils.attack_aux_funcs import visualize_perturbations


class OnePixelAttack:
    """
    This class implements the black-box adversarial attack One Pixel Attack (OPA).
    """

    def __init__(
        self, model: nn.Module, img: torch.Tensor, label: int, target_label, n: int = 100
    ) -> None:
        """
        Constructor of the class. Takes into account the difference between targeted and non-targeted
        attacks. The main difference is that in the targeted attack (specified by the use of the 
        target_label argument) the objective is to maximize the probability of the target class, while in the non-targeted attack
        the objective is to minimize the probability of the original class (thus, _fitness_function differs in both cases).

        Parameters
        ----------
        model : Model used.
        img   : Original image. Dimensions: [channels, height, width].
        label : Real label for the image.
        n     : Size of the population.
        target_label : Target label for the attack. If None, it is a non-targeted attack.
        """

        # Class attributes
        self.n = n
        self.F = 0.5
        self.img = img
        self.perturbed_img = img.clone()
        self.label = label
        self.target_label = target_label
        # Track whether we use GPU or CPU
        self.device = img.device
        self.model = model.to(self.device)

        # Create and evaluate population
        self.population = torch.rand(n, 5, device=self.device)
        self.fitness = self._evaluate_population()
        with torch.no_grad():
            prob = self.model(img.unsqueeze(0)).squeeze()
        self.historical_fitness = [F.softmax(prob, dim=0)[self.label].item()]

    @staticmethod
    def _add_perturbation(
        perturbations: list[torch.Tensor], img: torch.Tensor
    ) -> torch.Tensor:
        """
        Adds a finite number of perturbations (specifically len(perturbations)).

        Parameters
        ----------
        perturbations : Perturbations to made. Dimensions of each perturbation: [5].
        img           : Image to which perturbations are applied. Dimensions: [channels,
                        height, width].

        Returns
        -------
        p_ img : Perturbed image. Dimensions: [channels, height, width].
        """

        # TODO
        p_img = torch.clone(img)
        _, height, width = img.shape

        for p in perturbations:
            x = torch.clip(torch.round(height * p[0]).int(), 0, height - 1)
            y = torch.clip(torch.round(width * p[1]).int(), 0, width - 1)
            p_img[:, x, y] = p[2:]

        return p_img

    def _fitness_function(self, perturbed_img: torch.Tensor) -> float:
        """
        Calculates the fitness of the perturbed image generated by an individual. Allows for both targeted and non-targeted attacks

        Parameters
        ----------
        perturbed_img : Perturbed image generated by an individual. Dimensions:
                        [channels, height, width].

        Returns
        -------
        Probability asigned by the model to the real class.
        """

        with torch.no_grad():
            prob = self.model(perturbed_img.unsqueeze(0)).squeeze()

        target_idx = self.target_label if self.target_label is not None else self.label
        return F.softmax(prob, dim=0)[target_idx].item()

        # return F.softmax(prob, dim=0)[self.label].item()

    def _evaluate_population(self) -> torch.Tensor:
        """
        Evaluates the fitness of the entire population.

        Returns
        -------
        fitness : Fitness of the entire population. Dimensions: [self.n, 1].
        """
        # Allow for batch processing
        perturbed_imgs = torch.stack([
            self._add_perturbation([p], self.perturbed_img) for p in self.population
        ]).to(self.device)

        with torch.no_grad():
            logits = self.model(perturbed_imgs)
            probs = F.softmax(logits, dim=1)
            # return probs[:, self.label].detach().cpu().unsqueeze(1)
            target_idx = self.target_label if self.target_label is not None else self.label
            return probs[:, target_idx].detach().cpu().unsqueeze(1)

    def _generate_new_population(self) -> None:
        """
        Updates the population based on the algorithm x_i = x_r1 + F * (x_r2 - x_r3)
        and selects the best between each child and parent.
        """
        # Allow for both targeted and non-targeted attacks
        is_targeted = self.target_label is not None
        new_population = []
        new_fitness = []
        for i in range(self.n):
            # Select three random indices
            r1, r2, r3 = np.random.choice(self.n, size=3, replace=False)
            # Calculate new generation for parent i
            candidate = self.population[r1] + self.F * (
                self.population[r2] - self.population[r3]
            )

            # Ensure correct device
            candidate = candidate.to(self.device)

            # Calculate the fitness of using this child
            value = self._fitness_function(
                self._add_perturbation([candidate], self.perturbed_img)
            )

            # If is better, keep it instead of the parent. If not, use the parent. Use correct logic depending on whether it is a targeted or non-targeted attack
            if (value > self.fitness[i] if is_targeted else value < self.fitness[i]):
                new_population.append(candidate)
                new_fitness.append(value)
            else:
                new_population.append(self.population[i])
                new_fitness.append(self.fitness[i].item())

        # Update population and fitness values
        self.population = torch.stack(new_population).to(self.device)
        self.fitness = torch.tensor(new_fitness).unsqueeze(1)

    def _get_perturbations(
        self, epochs: int, d: int, print_every: int
    ) -> list[torch.Tensor]:
        """
        Obtains the perturbations using differential evolution.

        Parameters
        ----------
        epochs      : Number of epochs we train.
        d           : Number of pixels we change.
        print_every : Number of epochs we print the training phase.

        Returns
        -------
        perturbations : Bet perturbations found. Dimensions of each perturbation: [5].
        """
        # Restart the perturbed image buffer (Explained later)
        self.perturbed_img = self.img.clone()

        # Buffer for the perturbations
        perturbations = []
        # We will iterate in the number of pixels changed
        for j in range(d):
            # For j number of pixels, randomize a new population and restart
            # their fitness values
            self.population = torch.rand(self.n, 5, device=self.device)
            self.fitness = self._evaluate_population()

            # Train the population for all the epochs
            for i in range(epochs):
                # Evolve the population
                self._generate_new_population()

                if print_every and i % print_every == 0:
                    print(f"Pixel nÂº{j+1} Epoch {i}: Perturbations = {self.population}")

            # Obtain the pixel of the population that better perturbes the
            # image for j number of perturbations
            min_fitness_idx = torch.argmin(self.fitness, dim=0)
            perturbations.append(self.population[min_fitness_idx].squeeze())

            # Update the perturbed image (to measure the accumulated effect of the
            # number of pixels) this is essential since for evaluating the
            # behaviour of the next population with j+1 pixels you need to
            # have the image already perturbed with j pixels
            self.perturbed_img = self._add_perturbation(
                self.population[min_fitness_idx], self.perturbed_img  # type: ignore
            )

        return perturbations

    def perturb_img(
        self,
        print_every,
        epochs: int = 50,
        d: int = 1,
        show: bool = True,
        title: str = "",
    ) -> tuple[torch.Tensor, list[torch.Tensor]]:
        """
        Perturbs an image.

        Parameters
        ----------
        epochs      : Number of epochs we train.
        d           : Number of pixels we change.
        print_every : Number of epochs we print the training phase.
        show        : Boolean parameter that decides whether to save the figure or not.
        title       : Title of the image in case it is saved.

        Returns
        -------
        perturbed_img : Perturbed image. Dimensions: [channels, height, width].
        perturbations : Perturbations made. Dimensions of each perturbation: [channels,
                        height, width].
        """
        # Obtain the perturbations
        perturbations = self._get_perturbations(epochs, d, print_every)
        # Apply perturbations for obtaining the perturbed image
        perturbed_img = self._add_perturbation(perturbations, self.img)

        if show:
            visualize_perturbations(
                perturbed_img, self.img, self.label, self.model, title
            )

        return (perturbed_img, perturbations)
